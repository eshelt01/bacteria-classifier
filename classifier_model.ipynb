{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "#%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_validate_gen(model_type, rescaling_factor, image_path, batch_size):\n",
    "    # Create train and validate generators for bacteria data from ImageDataGenerator \n",
    "\n",
    "    if 'resnet' in model_type :\n",
    "        train_datagen = ImageDataGenerator(rescale = rescaling_factor,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True,\n",
    "                    vertical_flip = True,                   \n",
    "                    validation_split = 0.2,\n",
    "                    preprocessing_function = preprocess_input)  # Use specific data preprocessing for resnet\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        train_datagen = ImageDataGenerator(rescale = rescaling_factor,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True,\n",
    "                    vertical_flip = True,                   \n",
    "                    validation_split = 0.2,)      \n",
    "        \n",
    "    # Train and validate generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "                  image_path,\n",
    "                  target_size = (224,224),\n",
    "                  batch_size = batch_size,\n",
    "                  class_mode = 'categorical',\n",
    "                  subset = 'training')\n",
    "    \n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "                       image_path, \n",
    "                       target_size = (224, 224),\n",
    "                       batch_size= batch_size,\n",
    "                       class_mode='categorical',\n",
    "                       subset='validation')    # set as validation data)\n",
    "    \n",
    "    \n",
    "    return train_datagen, train_generator, validation_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_head(baseModel, dense1, dropout1, num_classes):\n",
    "    # Create model head to put atop pre-trained networks\n",
    "    \n",
    "    headModel = baseModel.output\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.2)(headModel)\n",
    "    headModel = Dense(33, activation=\"softmax\")(headModel)\n",
    "    \n",
    "    return headModel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_head_model(init_lr, batch_size, num_epochs, train_generator, validation_generator, callbacks):\n",
    "    # Compile and train the head model component\n",
    "    \n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = Adam(lr = init_lr, decay = init_lr / num_epochs)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "    print(\"[INFO] training head...\")\n",
    "    model.fit(train_generator,\n",
    "              steps_per_epoch = train_generator.samples // batch_size,\n",
    "              validation_data = validation_generator, \n",
    "              validation_steps = validation_generator.samples // batch_size,\n",
    "              epochs = num_epochs,\n",
    "              callbacks=[tensorboard_callback])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # VGG16 Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 514 images belonging to 33 classes.\n",
      "Found 109 images belonging to 33 classes.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/35\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.5392 - accuracy: 0.0625WARNING:tensorflow:From C:\\Users\\Ed\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "16/16 [==============================] - 159s 10s/step - loss: 4.7971 - accuracy: 0.1211 - val_loss: 2.3992 - val_accuracy: 0.3125\n",
      "Epoch 2/35\n",
      "16/16 [==============================] - 165s 10s/step - loss: 2.3798 - accuracy: 0.3008 - val_loss: 1.7486 - val_accuracy: 0.4688\n",
      "Epoch 3/35\n",
      " 7/16 [============>.................] - ETA: 58s - loss: 1.9594 - accuracy: 0.3557 "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# VGG16 Model Parameters \n",
    "model_type = 'vgg16'\n",
    "num_epochs = 35 \n",
    "batch_size = 32\n",
    "init_lr = 1e-3\n",
    "rescaling_factor = 1./255\n",
    "image_path = './Bacteria/Train'\n",
    "\n",
    "# Data generators\n",
    "train_datagen, train_generator, validation_generator = create_train_validate_gen(model_type, rescaling_factor, image_path, batch_size) \n",
    "\n",
    "# Create base model\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Freeze kayers of base model\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create head model\n",
    "headModel = create_model_head(baseModel, 512, 0.2, 33)\n",
    "\n",
    "# Place the head FC model on top of the base model \n",
    "model = Model(inputs = baseModel.input, outputs = headModel)\n",
    "   \n",
    "# Create log directory for train and validate and callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "\n",
    "# Train model head\n",
    "train_head_model(init_lr, batch_size, num_epochs, train_generator, validation_generator, tensorboard_callback)    \n",
    "   \n",
    "\n",
    "# Save model    \n",
    "model.save('/models/Vgg16_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 514 images belonging to 33 classes.\n",
      "Found 109 images belonging to 33 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# ResNet50 Model Parameters \n",
    "model_type = 'resnet50'\n",
    "num_epochs = 50 \n",
    "batch_size = 32\n",
    "init_lr = 1e-3\n",
    "rescaling_factor = None\n",
    "image_path = './Bacteria/Train'\n",
    "\n",
    "# Data generators\n",
    "train_datagen, train_generator, validation_generator = create_train_validate_gen(model_type, rescaling_factor, image_path, batch_size) \n",
    "\n",
    "# Create base model\n",
    "baseModel = ResNet50(include_top=False, weights = 'imagenet', input_tensor=Input(shape=(224, 224, 3)), pooling = 'avg')\n",
    "\n",
    "# Freeze kayers of base model\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create head model\n",
    "headModel = create_model_head(baseModel, 1024, 0.2, 33)\n",
    "\n",
    "# Place the head FC model on top of the base model \n",
    "model = Model(inputs = baseModel.input, outputs = headModel)\n",
    "   \n",
    "# Create log directory for train and validate and callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "\n",
    "# Train model head\n",
    "train_head_model(init_lr, batch_size, num_epochs, train_generator, validation_generator, tensorboard_callback)    \n",
    "   \n",
    "\n",
    "# Save model    \n",
    "model.save('/models/ResNet50_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor board\n",
    "\n",
    "%tensorboard --logdir=logs/fit --host localhost --port 8088"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
